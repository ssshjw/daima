{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "from docx import Document\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_punctuation_in_list(text_list):\n",
    "    replacements = {\n",
    "        '车道道宽(m)':'车行道宽(m)',\n",
    "        '桥梁桩号':'桥位桩号',\n",
    "        '引道线形(m)':'引道线形',\n",
    "        '引道线型':'引道线形',\n",
    "        '存档案':'存档号',\n",
    "        '桥下净空(m)':'桥下净高(m)',\n",
    "        '历次维修资料':'历史维修资料',\n",
    "        '机动车道宽':'车行道宽',\n",
    "        'f支座形式':'支座形式',\n",
    "        '（': '(',\n",
    "        '）': ')',\n",
    "        '跨经(m)':'跨径(m)',\n",
    "        '线路编号':'路线编号',\n",
    "        '线路名称':'路线名称',\n",
    "        '建成年月':'建成年限',\n",
    "        '引道路面宽':'引道路面宽(m)',\n",
    "        '线路名称':'路线名称',\n",
    "        '线路名称':'路线名称',\n",
    "        \n",
    "    }\n",
    "    \n",
    "    unified_list = []\n",
    "    for text in text_list:\n",
    "        for ch, replacement in replacements.items():\n",
    "            text = text.replace(ch, replacement)\n",
    "        unified_list.append(text)\n",
    "    \n",
    "    return unified_list\n",
    "\n",
    "\n",
    "def remove_blanks(text:str):\n",
    "    return re.sub(r'\\s', '', text)\n",
    "\n",
    "\n",
    "def remove_punctuations_and_blanks(text:str):\n",
    "    pattern = re.compile(r'[\\u4e00-\\u9fffA-Za-z0-9]+')\n",
    "    words = pattern.findall(text)\n",
    "    return ''.join(words)\n",
    "\n",
    "\n",
    "def find_doc_files(directory:str):\n",
    "    doc_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".docx\"):\n",
    "                doc_files.append(os.path.join(root, file))\n",
    "    return doc_files\n",
    "\n",
    " \n",
    "def find_doc_files_without_walking(directory: str):\n",
    "    doc_files = []\n",
    "    for entry in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        if os.path.isfile(full_path) and entry.endswith(\".docx\"):\n",
    "            doc_files.append(full_path)\n",
    "    return doc_files\n",
    "\n",
    "\n",
    "def clean_row(row_data:list):\n",
    "    cleaned_row = []\n",
    "    shang = []\n",
    "    previous_text = None\n",
    "    \n",
    "    if row_data[0] in [\"上\", \"部\", \"结\",\"构\",\"上部结构\"]:\n",
    "        shang.append(row_data)\n",
    "        \n",
    "    else:   \n",
    "        for text in row_data:\n",
    "            if text != previous_text:\n",
    "                cleaned_row.append(text)\n",
    "                previous_text = text\n",
    "    return cleaned_row,shang\n",
    "\n",
    "\n",
    "def read_data_from_row(row_data:list):\n",
    "    result = {}\n",
    "    if len(row_data)%3 == 0:\n",
    "        for i in range(len(row_data)//3):\n",
    "            result[row_data[3*i+1]] = [row_data[3*i+2]]\n",
    "    elif len(row_data) == 4:\n",
    "        result[row_data[2]] = [row_data[3]]\n",
    "    return result\n",
    "\n",
    "\n",
    "def read_data_from_shangbujiegou(row_data:list):  \n",
    "    result = {}\n",
    "    targets = [['下部结构','下部结构','下部结构','下部结构'],['下','部','结','构']]\n",
    "    for target in targets:\n",
    "        if target in row_data:\n",
    "            index = row_data.index(target)\n",
    "    for i in range(index-3):\n",
    "        result[f'{row_data[2]}{i+1}'] = \"@\".join(row_data[i+3])\n",
    "    for j in range(len(row_data)-index-3):\n",
    "        result[f'{row_data[index+2]}{j+1}'] = \"@\".join(row_data[index+j+3])        \n",
    "    return result\n",
    "\n",
    "\n",
    "def clean_cell(cell):\n",
    "    if isinstance(cell, list) and len(cell) > 0:\n",
    "        # 如果是非空列表，去掉列表符号和内容的引号\n",
    "        return str(cell[0]).strip(\"'[]\")\n",
    "    elif isinstance(cell, list):\n",
    "        # 如果是空列表，返回空字符串\n",
    "        return ''\n",
    "    else:\n",
    "        # 如果不是列表，直接返回内容\n",
    "        return str(cell).strip(\"'[]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_static_1(document: docx.Document)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function responsible for extracting the static data table from inspection reports\n",
    "    This function works for reports in 2023 and 2022, where there is one large table containing all the information\n",
    "\n",
    "    Args:\n",
    "        document (docx.Document): inspection report document\n",
    "\n",
    "    Returns:\n",
    "        extracted_data (pd.DataFrame): extracted data, in which 1 row represents 1 bridge\n",
    "    \"\"\"\n",
    "\n",
    "    extracted_data = pd.DataFrame([])\n",
    "\n",
    "    for table in document.tables:\n",
    "        if \"桥梁所处行政区划代码\" in remove_blanks(table.rows[0].cells[0].text):\n",
    "            table_content = {}\n",
    "            for row in table.rows:\n",
    "                row_content = clean_row([remove_blanks(cell.text) for cell in row.cells])\n",
    "                \n",
    "                table_content.update(read_data_from_row(row_content))\n",
    "            table_content = pd.DataFrame(table_content)\n",
    "            extracted_data = pd.concat([extracted_data, table_content], ignore_index=True, axis=0)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def extract_static_2(document: docx.Document)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function responsible for extracting the static data table from inspection reports\n",
    "    This function works for reports in 2021 S32,同三,沪芦, where there is one large table containing all the information\n",
    "\n",
    "    Args:\n",
    "        document (docx.Document): inspection report document\n",
    "\n",
    "    Returns:\n",
    "        extracted_data (pd.DataFrame): extracted data, in which 1 row represents 1 bridge\n",
    "    \"\"\"\n",
    "\n",
    "    columns_to_delete = ['竣工', '工程范围','质量评定','施工单位','主要负责人','填卡人','填卡日期']\n",
    "    extracted_data = pd.DataFrame([])\n",
    "\n",
    "    for table in document.tables:\n",
    "        if \"行政识别数据\" in remove_blanks(table.rows[0].cells[0].text):\n",
    "            table_content = {}\n",
    "            for row in table.rows:\n",
    "                row_content = clean_row([remove_blanks(cell.text) for cell in row.cells])\n",
    "                print(f'row_content:{row_content}')\n",
    "                table_content.update(read_data_from_row(row_content))\n",
    "                print(f'table_content:{table_content}')\n",
    "            table_content = pd.DataFrame(table_content)\n",
    "            table_content.drop(columns=columns_to_delete, inplace=True)\n",
    "            extracted_data = pd.concat([extracted_data, table_content], ignore_index=True, axis=0)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def extract_static_3(document: docx.Document) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function responsible for extracting the static data table from inspection reports\n",
    "\n",
    "    Args:\n",
    "        document (docx.Document): inspection report document\n",
    "\n",
    "    Returns:\n",
    "        extracted_data (pd.DataFrame): extracted data, where 1 row represents 1 bridge\n",
    "    \"\"\"\n",
    "\n",
    "    extracted_data = pd.DataFrame([])\n",
    "    one_bridge_data = {}\n",
    "\n",
    "    for block in document.iter_inner_content():\n",
    "        if type(block) == docx.text.paragraph.Paragraph:  # if it is a paragraph\n",
    "            text = remove_punctuations_and_blanks(block.text)\n",
    "            if \"桥梁基本状况卡片\" in text:\n",
    "                # If there is already data in one_bridge_data, add it to extracted_data before starting new bridge\n",
    "                if one_bridge_data:\n",
    "                    extracted_data = pd.concat([extracted_data, pd.DataFrame([one_bridge_data])], ignore_index=True)\n",
    "                    one_bridge_data = {}  # Reset for new bridge\n",
    "        elif type(block) == docx.table.Table:\n",
    "            if (\"行政识别数据\" in remove_blanks(block.rows[0].cells[0].text)) or (\"结构技术数据\" in remove_blanks(block.rows[0].cells[0].text)):\n",
    "                vertical_content = []\n",
    "                for row in block.rows:\n",
    "                    row_content = clean_row([remove_blanks(cell.text) for cell in row.cells])\n",
    "                    if row_content[0] in [\"上\", \"部\", \"结\",\"构\"]:  # Collect vertical data\n",
    "                        vertical_content.append(row_content)\n",
    "                    one_bridge_data.update(read_data_from_row(row_content))  # Process and update the data\n",
    "                \n",
    "\n",
    "    # Add the last bridge's data if any remains\n",
    "    if one_bridge_data:\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame([one_bridge_data])], ignore_index=True)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def extract_static_4(document: docx.Document) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function responsible for extracting the static data table from inspection reports\n",
    "    This function works for reports in 2021、2020、2019、2018, where there is one large table containing all the information\n",
    "\n",
    "    Args:\n",
    "        document (docx.Document): inspection report document\n",
    "\n",
    "    Returns:\n",
    "        extracted_data (pd.DataFrame): extracted data, where 1 row represents 1 bridge\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    columns_to_delete = ['竣工', '工程范围','质量评定','施工单位']\n",
    "    target_paragraphs = ['行政识别数据', '结构技术数据','档案资料（全、不全或无）','档案资料(全、不全或无)']\n",
    "    extracted_data = pd.DataFrame([])      \n",
    "    table_content = {}\n",
    "    current_paragraph = None \n",
    "    shangbujiegou = []\n",
    "    cleaned_row = []\n",
    "    previous_text = None \n",
    "    \n",
    "    for element in document.element.body:\n",
    "        if element.tag.endswith('tbl') and current_paragraph == None:\n",
    "            table = docx.table.Table(element, document)\n",
    "            if (\"行政识别数据\" in remove_blanks(table.rows[0].cells[0].text)) or (\"结构技术数据\" in remove_blanks(table.rows[0].cells[0].text)) or (\"档案资料（全、不全或无）\" in remove_blanks(table.rows[0].cells[0].text)):\n",
    "                for row in table.rows:\n",
    "                    row_content,shang = clean_row([remove_blanks(cell.text) for cell in row.cells])\n",
    "                    if shang == []:\n",
    "                        pass\n",
    "                    else:\n",
    "                        shang[0] = unify_punctuation_in_list(shang[0])\n",
    "                        shangbujiegou.append(shang)\n",
    "                    row_content = unify_punctuation_in_list(row_content)\n",
    "                    print(f\"row_content: {row_content}\")\n",
    "                    print(f\"shang: {shang}\")\n",
    "                    if row_content:\n",
    "                       print('进row_content了')\n",
    "                       table_content.update(read_data_from_row(row_content))\n",
    "                    elif shang: \n",
    "                        print('进shang了')\n",
    "                        print(shangbujiegou)        \n",
    "                        if len(shangbujiegou) == 4:  # Collect vertical data \n",
    "                            l1 = shangbujiegou[0][0]\n",
    "                            l2 = shangbujiegou[1][0]\n",
    "                            l3 = shangbujiegou[2][0]\n",
    "                            l4 = shangbujiegou[3][0]\n",
    "                            print(l1)\n",
    "                            print(l2)\n",
    "                            print(l3)\n",
    "                            print(l4)\n",
    "                            a = list(zip(l1, l2, l3, l4))\n",
    "                            b = [list(item) for item in a if not any(x == '' for x in item)]\n",
    "                            print(a)\n",
    "                            print(b)\n",
    "                            for text in b:\n",
    "                                if text != previous_text:\n",
    "                                    cleaned_row.append(text)\n",
    "                                    previous_text = text#处理\n",
    "                            print(cleaned_row)\n",
    "                            table_content.update(read_data_from_shangbujiegou(cleaned_row))\n",
    "                            shangbujiegou = []\n",
    "                            cleaned_row = []\n",
    "                    else:\n",
    "                        print('wrong')\n",
    "                        \n",
    "                    print(f'table_content: {table_content}')\n",
    "                if table_content:\n",
    "                    extracted_data = pd.concat([extracted_data, pd.DataFrame(table_content)], ignore_index=True)\n",
    "                    extracted_data.drop(columns=columns_to_delete, inplace=True)\n",
    "                    \n",
    "                    \n",
    "        elif element.tag.endswith('p'):\n",
    "                paragraph = element.xpath(\".//text()\")\n",
    "                paragraph_text = ''.join(paragraph).strip()\n",
    "                for target in target_paragraphs:\n",
    "                    if target in paragraph_text:\n",
    "                        current_paragraph = target\n",
    "                        print(current_paragraph)\n",
    "                        break                                  \n",
    "        elif element.tag.endswith('tbl') and current_paragraph: \n",
    "            table = docx.table.Table(element, document)\n",
    "            for row in table.rows:\n",
    "                row_content,shang = clean_row([remove_blanks(cell.text) for cell in row.cells])\n",
    "                if shang == []:\n",
    "                    pass\n",
    "                else:\n",
    "                    shang[0] = unify_punctuation_in_list(shang[0])\n",
    "                    shangbujiegou.append(shang)\n",
    "                row_content = unify_punctuation_in_list(row_content)\n",
    "                print(f\"row_content: {row_content}\")\n",
    "                print(f\"shang: {shang}\")\n",
    "                if row_content:\n",
    "                    print('进row_content了')\n",
    "                    table_content.update(read_data_from_row(row_content))\n",
    "                elif shang:  \n",
    "                    print('进shang了')\n",
    "                    print(f'shangbujiegou:{shangbujiegou}')       \n",
    "                    if len(shangbujiegou) == 4:  # Collect vertical data \n",
    "                        l1 = shangbujiegou[0][0]\n",
    "                        l2 = shangbujiegou[1][0]\n",
    "                        l3 = shangbujiegou[2][0]\n",
    "                        l4 = shangbujiegou[3][0]\n",
    "                        print(l1)\n",
    "                        print(l2)\n",
    "                        print(l3)\n",
    "                        print(l4)\n",
    "                        a = list(zip(l1, l2, l3, l4))\n",
    "                        b = [list(item) for item in a if not any(x == '' for x in item)]\n",
    "                        print(a)\n",
    "                        print(b)\n",
    "                        for text in b:\n",
    "                            if text != previous_text:\n",
    "                                cleaned_row.append(text)\n",
    "                                previous_text = text#处理\n",
    "                        print(cleaned_row)\n",
    "                        table_content.update(read_data_from_shangbujiegou(cleaned_row))\n",
    "                        shangbujiegou = []\n",
    "                        cleaned_row = []\n",
    "                else:\n",
    "                    print('wrong')\n",
    "                print(f'table_content: {table_content}')\n",
    "            current_paragraph = None                               \n",
    "            if table_content:\n",
    "                extracted_data = pd.concat([extracted_data, pd.DataFrame(table_content)], ignore_index=True)\n",
    "                extracted_data.drop(columns=columns_to_delete, inplace=True)\n",
    "               \n",
    "            \n",
    "        \n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    '线路编号': '路线编号', \n",
    "    '线路名称': '路线名称',\n",
    "    '建成时间':'建成年限',\n",
    "    '建成年月':'建成年限',\n",
    "    '引道路面宽':'引道路面宽(m)',\n",
    "    '引道总宽（m）':'引道总宽(m)',\n",
    "    '调制构造':'调制构造物',\n",
    "    '设计文献':'设计文件',\n",
    "    '历次维修资料':'历史维修资料',\n",
    "    '历次维修、加固资料':'历史维修资料',\n",
    "    '290':'墩台',\n",
    "    '291':'墩台',\n",
    "    '300':'形式',\n",
    "    '301':'形式',\n",
    "    '310':'材料',\n",
    "    '311':'材料',\n",
    "    '桥梁分孔':'桥梁分孔（m）',\n",
    "    '桥下实际净空':'桥下实际净空(m)',\n",
    "    '车道宽度':'车道宽度(m)',\n",
    "    '人行道宽度(m)':'人行道宽度（m）',\n",
    "    '中央分隔带宽度(m)':'中央分隔带宽度（m）',\n",
    "    '桥面实际净空(m)':'桥面实际净空（m）',\n",
    "    '桥下通航等级及标准净空(m)':'桥下通航等级及标准净空（m）',\n",
    "    '桥下实际净空(m)':'桥下实际净空（m）',\n",
    "    '引道线形或曲线半径(m)':'引道线形或曲线半径（m）',\n",
    "    '桥梁全宽(m)':'桥面总宽(m)',\n",
    "   \n",
    "    \n",
    "\n",
    "    # 添加更多列名映射...\n",
    "}\n",
    "\n",
    "input_dir = \"D:\\\\statics\\\\Reports\\\\2022\\\\沪莘枫1标-.docx\"\n",
    "output_dir = \"D:\\\\statics\\\\statics\\\\沪莘枫1标\"\n",
    "doc_files = find_doc_files_without_walking(input_dir)\n",
    "for doc_file in doc_files: \n",
    "    try:       \n",
    "        input_file = os.path.abspath(doc_file)\n",
    "        relative_path = os.path.relpath(doc_file, start=input_dir)\n",
    "        output_file_path = os.path.join(output_dir, relative_path[0:-4] + 'xlsx')\n",
    "        document = Document(doc_file)\n",
    "        extracted_data = extract_static_1(document=document)\n",
    "        extracted_data.rename(columns=column_mapping, inplace=True)\n",
    "        for col in ['...','立面照','平面照','定期检查','2类`','1类','3类','','2类','/','桥梁总体照片','桥梁正面照片','桥梁侧面照片','37','较好','下次检测','预应力T梁','桥面总宽(m).1']:\n",
    "            if col in extracted_data.columns:\n",
    "                print(doc_file)\n",
    "                extracted_data = extracted_data.drop(columns = col)\n",
    "            extracted_data.to_excel(output_file_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error occured at file {doc_file}\\nError mesasage {e}\")    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"D:\\\\statics\\\\Reports\\\\2020\\\\20年S32\"\n",
    "output_dir = \"D:\\\\statics\\\\statics\\\\S32\\\\20年S32\"\n",
    "doc_files = find_doc_files(input_dir)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for doc_file in doc_files:\n",
    "    input_file = os.path.abspath(doc_file)\n",
    "    relative_path = os.path.relpath(doc_file, start=input_dir)\n",
    "    output_file_path = os.path.join(output_dir, relative_path[0:-4] + 'xlsx')\n",
    "    document = Document(doc_file)\n",
    "    extracted_data = extract_static_4(document=document)\n",
    "    for col in ['定期检测','修复养护、预防养护','立面照','平面照','定期检查','1类','3类','','2类','/','2010','北京市海龙公路工程公司','']:\n",
    "            if col in extracted_data.columns:\n",
    "                print(doc_file)\n",
    "                extracted_data = extracted_data.drop(columns = col)\n",
    "            cleaned_data = extracted_data.apply(lambda x: x.map(clean_cell))\n",
    "    \n",
    "    cleaned_data.to_excel(output_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
